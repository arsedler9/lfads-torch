defaults:
  - scheduler: fifo
  # Use colored logger
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog
  - _self_

run_tag: ???
runs_home: /snel/share/runs/lfads-torch/testing
config_train: multi_train.yaml

ray_tune_run:
  metric: valid/recon
  mode: min
  name: ${run_tag}
  resources_per_trial:
    cpu: 2
    gpu: 0.3
  # TODO: Debug for deterministic samples
  # search_alg:
  #   _target_: ray.tune.suggest.basic_variant.BasicVariantGenerator
  #   random_state: 0
  num_samples: 30
  # With `name`, a hack to get `ray.tune` to use the directory created by `hydra`.
  local_dir: ".."
  verbose: 1

search_space:
  model:
    dropout_rate:
      _target_: ray.tune.uniform
      lower: 0.0
      upper: 0.7
    l2_ic_enc_scale:
      _target_: ray.tune.loguniform
      lower: 1.0e-5
      upper: 1.0e-3
    l2_ci_enc_scale:
      _target_: ray.tune.loguniform
      lower: 1.0e-5
      upper: 1.0e-3
    l2_gen_scale:
      _target_: ray.tune.loguniform
      lower: 1.0e-5
      upper: 1.0e-0
    l2_con_scale:
      _target_: ray.tune.loguniform
      lower: 1.0e-5
      upper: 1.0e-0
    kl_co_scale:
      _target_: ray.tune.loguniform
      lower: 1.0e-6
      upper: 1.0e-3
    kl_ic_scale:
      _target_: ray.tune.loguniform
      lower: 1.0e-6
      upper: 1.0e-3

progress_reporter:
  _target_: ray.tune.CLIReporter
  metric_columns:
    - valid/recon
    - cur_epoch
  sort_by_metric: True

hydra:
  run:
    dir: ${runs_home}/multi/${run_tag}
  output_subdir: null
